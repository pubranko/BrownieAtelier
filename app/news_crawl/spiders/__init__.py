# This package will contain the spiders of your Scrapy project
#
# Please refer to the documentation for information on how to create and manage
# your spiders.

#####################
# from twisted.python import log
# import logging
# LOG_FILE = "logs/spider.log"
# ERR_FILE = "logs/spider_error.log"
# logging.basicConfig(level=logging.INFO, filemode="w+", filename=LOG_FILE)
# logging.basicConfig(level=logging.ERROR, filemode="w+", filename=ERR_FILE)
# observer = log.PythonLoggingObserver()
# observer.start()

# import logging
# from logging import Logger,StreamHandler

# loggers = [logging.getLogger(name) for name in logging.root.manager.loggerDict]
# for logger in loggers:
#     logger:Logger
#     print('=== spider __init__ logger:',logger.name,':',logger.handlers)
# logger = logging.getLogger('')  #root
# print('=== spider __init__ logger:',logger.name,':',logger.handlers)

import logging
# logging.getLogger('scrapy.core.engine').setLevel(logging.INFO)    #効果がなかった、、、
logging.getLogger('scrapy.core.scraper').setLevel(logging.INFO)
logging.getLogger('filelock').setLevel(logging.INFO)
